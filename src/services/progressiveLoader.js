/**
 * Progressive Loader Service
 *
 * Handles chunked loading of large datasets with progressive rendering
 * and intelligent retry logic for optimal user experience.
 */

class ProgressiveLoader {
  constructor() {
    this.activeLoads = new Map();
    this.defaultOptions = {
      chunkSize: 1000, // Features per chunk
      maxRetries: 3, // Max retry attempts per chunk
      retryDelay: 1000, // Base retry delay in ms
      timeout: 30000, // Request timeout in ms
      concurrency: 2, // Max concurrent chunk requests
      adaptiveChunking: true, // Adjust chunk size based on performance
    };
  }

  /**
   * Load data progressively in chunks
   * @param {string} url - Data source URL
   * @param {Object} options - Loading options
   * @returns {Promise} Promise that resolves with complete data
   */
  async loadData(url, options = {}) {
    const config = { ...this.defaultOptions, ...options };
    const loadId = this.generateLoadId(url);

    try {
      // Store active load for potential cancellation
      const controller = new AbortController();
      this.activeLoads.set(loadId, controller);

      // First, get metadata about the dataset
      const metadata = await this.getDatasetMetadata(url, controller.signal);

      // Determine if progressive loading is beneficial
      if (!this.shouldUseProgressiveLoading(metadata, config)) {
        // Fall back to standard loading for small datasets
        return this.loadStandard(url, controller.signal, config);
      }

      // Load data progressively
      const result = await this.loadProgressively(
        url,
        metadata,
        controller.signal,
        config,
      );

      return result;
    } finally {
      this.activeLoads.delete(loadId);
    }
  }

  /**
   * Get dataset metadata to determine loading strategy
   */
  async getDatasetMetadata(url, signal) {
    try {
      // For GeoJSON, we might need to inspect the data structure
      // This is a simplified approach - in reality, you might have
      // specific endpoints that provide metadata
      const response = await fetch(url, {
        signal,
        method: "HEAD", // Try HEAD first to get size info
      });

      const contentLength = response.headers.get("content-length");

      return {
        estimatedSize: contentLength ? parseInt(contentLength) : null,
        contentType: response.headers.get("content-type"),
        supportsRangeRequests:
          response.headers.get("accept-ranges") === "bytes",
      };
    } catch (error) {
      // If HEAD fails, we'll proceed with progressive loading anyway
      console.warn("Could not get dataset metadata:", error);
      return {
        estimatedSize: null,
        contentType: "application/json",
        supportsRangeRequests: false,
      };
    }
  }

  /**
   * Determine if progressive loading should be used
   */
  shouldUseProgressiveLoading(metadata, config) {
    // Use progressive loading for:
    // 1. Large datasets (>100KB)
    // 2. Unknown size datasets (when explicitly requested)
    // 3. When config.forceProgressive is true

    if (config.forceProgressive) return true;

    if (metadata.estimatedSize) {
      return metadata.estimatedSize > 100000; // 100KB threshold
    }

    // Default to progressive for unknown sizes
    return true;
  }

  /**
   * Standard loading fallback
   */
  async loadStandard(url, signal, config) {
    const response = await fetch(url, {
      signal,
      timeout: config.timeout,
    });

    if (!response.ok) {
      throw new Error(`HTTP ${response.status}: ${response.statusText}`);
    }

    const data = await response.json();

    // Still call onProgress for consistency
    if (config.onProgress) {
      config.onProgress(1, 1);
    }

    return data;
  }

  /**
   * Load data progressively in chunks
   */
  async loadProgressively(url, metadata, signal, config) {
    // For most APIs, we can't actually chunk the requests
    // So we'll load the full data and then process it in chunks
    // This still provides progressive UI updates

    console.log("ðŸ”„ Starting progressive loading for:", url);

    // Load the complete dataset
    const response = await fetch(url, { signal, timeout: config.timeout });

    if (!response.ok) {
      throw new Error(`HTTP ${response.status}: ${response.statusText}`);
    }

    const fullData = await response.json();

    // Process data in chunks if it has features
    if (fullData.features && fullData.features.length > config.chunkSize) {
      return this.processDataInChunks(fullData, config);
    } else {
      // Small dataset, process normally
      if (config.onProgress) {
        config.onProgress(1, 1);
      }
      if (config.onChunk) {
        await config.onChunk(fullData);
      }
      return fullData;
    }
  }

  /**
   * Process large datasets in chunks for progressive rendering
   */
  async processDataInChunks(data, config) {
    const features = data.features;
    const totalFeatures = features.length;
    const chunkSize = config.adaptiveChunking
      ? this.calculateOptimalChunkSize(totalFeatures)
      : config.chunkSize;

    console.log(
      `ðŸ“¦ Processing ${totalFeatures} features in chunks of ${chunkSize}`,
    );

    let processedFeatures = 0;
    const processedChunks = [];

    for (let i = 0; i < features.length; i += chunkSize) {
      const chunk = features.slice(i, i + chunkSize);
      const chunkData = {
        ...data,
        features: chunk,
      };

      // Process chunk
      if (config.onChunk) {
        try {
          await config.onChunk(chunkData);
          processedChunks.push(chunkData);
        } catch (error) {
          console.error(
            `Error processing chunk ${Math.floor(i / chunkSize)}:`,
            error,
          );
          // Continue with other chunks
        }
      }

      processedFeatures += chunk.length;

      // Update progress
      if (config.onProgress) {
        config.onProgress(processedFeatures, totalFeatures);
      }

      // Yield control to prevent UI blocking
      await new Promise((resolve) => {
        if (window.requestIdleCallback) {
          requestIdleCallback(resolve, { timeout: 50 });
        } else {
          setTimeout(resolve, 0);
        }
      });
    }

    console.log(
      `âœ… Progressive processing complete: ${processedFeatures} features`,
    );

    // Return the original data structure
    return data;
  }

  /**
   * Calculate optimal chunk size based on dataset size and performance
   */
  calculateOptimalChunkSize(totalFeatures) {
    // Adaptive chunking based on dataset size
    if (totalFeatures < 500) return 100;
    if (totalFeatures < 2000) return 250;
    if (totalFeatures < 10000) return 500;
    return 1000;
  }

  /**
   * Cancel active loading operation
   */
  cancelLoad(url) {
    const loadId = this.generateLoadId(url);
    const controller = this.activeLoads.get(loadId);
    if (controller) {
      controller.abort();
      this.activeLoads.delete(loadId);
      console.log("ðŸ“› Cancelled progressive loading:", url);
    }
  }

  /**
   * Cancel all active loading operations
   */
  cancelAllLoads() {
    for (const [loadId, controller] of this.activeLoads) {
      controller.abort();
    }
    this.activeLoads.clear();
    console.log("ðŸ“› Cancelled all progressive loading operations");
  }

  /**
   * Generate unique load ID for tracking
   */
  generateLoadId(url) {
    return btoa(url).replace(/[/+=]/g, "").substring(0, 16);
  }

  /**
   * Get statistics about active loads
   */
  getLoadStats() {
    return {
      activeLoads: this.activeLoads.size,
      loadIds: Array.from(this.activeLoads.keys()),
    };
  }

  /**
   * Update default options
   */
  updateDefaults(newDefaults) {
    this.defaultOptions = { ...this.defaultOptions, ...newDefaults };
  }
}

// Create and export singleton instance
const progressiveLoader = new ProgressiveLoader();
export default progressiveLoader;
